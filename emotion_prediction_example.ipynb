{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "emotion_prediction_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Run Emotion-English-DistilRoBERTa-base on multiple text documents"
      ],
      "metadata": {
        "id": "TgE9B3kso7fQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIt7_lKp0h-"
      },
      "source": [
        "# install the transformers library\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wC0q6Bxp3or"
      },
      "source": [
        "# import required packages\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer\n",
        "\n",
        "# Create class for data preparation\n",
        "class SimpleDataset:\n",
        "    def __init__(self, tokenized_texts):\n",
        "        self.tokenized_texts = tokenized_texts\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.tokenized_texts[\"input_ids\"])\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return {k: v[idx] for k, v in self.tokenized_texts.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZNal9hXp6wm"
      },
      "source": [
        "# load tokenizer and model, create trainer\n",
        "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "trainer = Trainer(model=model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Option 1:** Create list of texts"
      ],
      "metadata": {
        "id": "qzFwNDGVpHeW"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEzNB5Up5Yc"
      },
      "source": [
        "# create list of texts (can be imported from .csv, .xls etc.)\n",
        "pred_texts = ['I like that', 'That is annoying', 'This is great!', 'WouldnÂ´t recommend it.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Option 2:** Upload file to temporary Google space"
      ],
      "metadata": {
        "id": "VseDjQ8upR4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run cell and select file for upload\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "uX3xjKZxq5iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify your filename\n",
        "file_name = \"/content/YOUR_FILENAME.csv\"  # note: you can right-click on your file and copy-paste the path to it here\n",
        "text_column = \"text\"  # select the column in your csv that contains the text to be classified\n",
        "\n",
        "# read in csv\n",
        "df_pred = pd.read_csv(file_name)\n",
        "pred_texts = df_pred[text_column].dropna().astype('str').tolist()"
      ],
      "metadata": {
        "id": "R8O-BC4Zphdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Option 3:** Connect to Google Drive and select file"
      ],
      "metadata": {
        "id": "9UXy6qJApnKs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8cEaNRjxzLX"
      },
      "source": [
        "# import file stored on Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# specify your filename\n",
        "file_name = \"/content/YOUR_FILENAME.csv\"  # note: you can right-click on your file and copy-paste the path to it here\n",
        "text_column = \"text\"  # select the column in your csv that contains the text to be classified\n",
        "\n",
        "# read in csv\n",
        "df_pred = pd.read_csv(file_name)\n",
        "pred_texts = df_pred[text_column].dropna().astype('str').tolist()"
      ],
      "metadata": {
        "id": "ziV-AUW7rNbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify texts with model"
      ],
      "metadata": {
        "id": "PNauUHt1qPaM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKLUxGXmp7zF"
      },
      "source": [
        "# Tokenize texts and create prediction data set\n",
        "tokenized_texts = tokenizer(pred_texts,truncation=True,padding=True)\n",
        "pred_dataset = SimpleDataset(tokenized_texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5mjnob3sMCl"
      },
      "source": [
        "# Run predictions\n",
        "predictions = trainer.predict(pred_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3O53RHCsVd7"
      },
      "source": [
        "# Transform predictions to labels\n",
        "preds = predictions.predictions.argmax(-1)\n",
        "labels = pd.Series(preds).map(model.config.id2label)\n",
        "scores = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True)).max(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUBbYjnhmxop"
      },
      "source": [
        "# scores raw\n",
        "temp = (np.exp(predictions[0])/np.exp(predictions[0]).sum(-1,keepdims=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXuTJKMKhCbL"
      },
      "source": [
        "# work in progress\n",
        "# container\n",
        "anger = []\n",
        "disgust = []\n",
        "fear = []\n",
        "joy = []\n",
        "neutral = []\n",
        "sadness = []\n",
        "surprise = []\n",
        "\n",
        "# extract scores (as many entries as exist in pred_texts)\n",
        "for i in range(len(pred_texts)):\n",
        "  anger.append(temp[i][0])\n",
        "  disgust.append(temp[i][1])\n",
        "  fear.append(temp[i][2])\n",
        "  joy.append(temp[i][3])\n",
        "  neutral.append(temp[i][4])\n",
        "  sadness.append(temp[i][5])\n",
        "  surprise.append(temp[i][6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhIONI7ett0q"
      },
      "source": [
        "# Create DataFrame with texts, predictions, labels, and scores\n",
        "df = pd.DataFrame(list(zip(pred_texts,preds,labels,scores,  anger, disgust, fear, joy, neutral, sadness, surprise)), columns=['text','pred','label','score', 'anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export results"
      ],
      "metadata": {
        "id": "ehyrB3QxqYEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save results to csv\n",
        "YOUR_FILENAME = \"YOUR_FILENAME_EMOTIONS.csv\"  # name your output file\n",
        "df.to_csv(YOUR_FILENAME)"
      ],
      "metadata": {
        "id": "CN-p8nG7NAmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download file\n",
        "files.download(YOUR_FILENAME)"
      ],
      "metadata": {
        "id": "ZbdoUQ9tqenN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}