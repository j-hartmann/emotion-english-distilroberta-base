{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von emotion_prediction_example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkIt7_lKp0h-"
      },
      "source": [
        "# Install the transformers library\n",
        "!pip install transformers\n",
        "import torch\n",
        "import numpy as np \n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZNal9hXp6wm"
      },
      "source": [
        "# Load tokenizer and model, create trainer\n",
        "model_name = \"j-hartmann/emotion-english-distilroberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHEzNB5Up5Yc"
      },
      "source": [
        "# sentence to be analyzed\n",
        "sentence = \"What a beautiful day!\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKLUxGXmp7zF"
      },
      "source": [
        "# Tokenize texts and create prediction data set\n",
        "tokenized_texts = tokenizer(sentence, truncation=True, padding=True, return_tensors=\"pt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUoW2h0PmQFe"
      },
      "source": [
        "# Prediction\n",
        "# tensor ([1]) -> tensor([[1]])\n",
        "labels = torch.tensor([1]).unsqueeze(0)\n",
        "outputs = model(**tokenized_texts, labels=labels)\n",
        "loss, logits = outputs[:2]\n",
        "# tensor ([[]]) -> tensor ([])\n",
        "logits = logits.squeeze(0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ere2KWwmdlR"
      },
      "source": [
        "# Probabilities\n",
        "# perform softmax on logits\n",
        "probabilities_tensor = torch.nn.functional.softmax(logits, dim=0)\n",
        "\n",
        "# detaches tensor from graph, convert to numpy array\n",
        "probabilities_numpy = np.array(probabilities_tensor.detach().numpy())"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ers_jYYBs4F3"
      },
      "source": [
        "# Obtain emotion probabilities (sorted)\n",
        "emotion_labels = ['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'surprise']\n",
        "\n",
        "# sort np-array by values low-high, flip to high-low\n",
        "emotion_values = np.argsort(probabilities_numpy)[::-1]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8vPW4aCmgXe"
      },
      "source": [
        "# Print emotion labels with respective prediction values\n",
        "for emotion in range(len(probabilities_numpy)):\n",
        "    # current emotion\n",
        "    em = emotion_labels[emotion_values[emotion]]\n",
        "    # current probability\n",
        "    prob = probabilities_numpy[emotion_values[emotion]]\n",
        "    print(f\"{em}:\\n\" + f\"{np.round(float(prob), 10)}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}